{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7284f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import f\n",
    "from numpy.linalg import multi_dot\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import pinv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8bf99640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set format of the output\n",
    "float_formatter = \"{:.4f}\".format # keep 4 digits\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "#******************************************************************************\n",
    "# Define Paths + Read in Data + Clean Data\n",
    "#******************************************************************************\n",
    "# define paths of files \n",
    "path = os.getcwd() + \"/Data\"\n",
    "\n",
    "# path = '/Users/keling/Dropbox/Courses/Keling/aptest_keling/Data'\n",
    "FFFactors_path = '/factors/FFFactors.txt'\n",
    "FF25_path = '/FF25/ff25vm.txt'\n",
    "size10_path = '/size10/sizevm.txt'\n",
    "industry10_path = '/industry10/ind10vm.txt'\n",
    "sm25_path = '/SM/25sm.txt'\n",
    "FF3New_path = '/FF3/ff3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3bf801d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "FFFactors = pd.read_csv(path + FFFactors_path, header = None, delim_whitespace=True)\n",
    "FFFactors.columns = ['time', 'MKT-RF', 'SMB','HML', 'RF']\n",
    "\n",
    "# transform into matrix form\n",
    "rmx = FFFactors['MKT-RF'].to_numpy().reshape(-1,1) # market excess return \n",
    "rf = FFFactors['RF'].to_numpy().reshape(-1,1) # risk free rate\n",
    "\n",
    "FF25 = pd.read_csv(path + FF25_path, header = None, delim_whitespace=True)\n",
    "size10 = pd.read_csv(path + size10_path, header = None, delim_whitespace=True)\n",
    "industry10 = pd.read_csv(path + industry10_path, header = None, delim_whitespace=True)\n",
    "sm25 = pd.read_csv(path + sm25_path, header = None, delim_whitespace=True)\n",
    "FF3 = pd.read_csv(path + FF3New_path, header = None, delim_whitespace=True)\n",
    "FF3.columns = ['time', 'MKT-RF', 'SMB','HML', 'RF']\n",
    "# select test assets\n",
    "# ta = 1: Fama-French 25 portfolios\n",
    "# ta = 2: 10 size deciles\n",
    "# ta = 3: 10 industry portfolios\n",
    "# ta = 4: size and value factors - SMB and HML\n",
    "\n",
    "ta = 0\n",
    "if ta ==0:\n",
    "    testass = sm25.iloc[:,1:26].to_numpy()\n",
    "if ta ==1:\n",
    "    testass = FF25.iloc[:,1:26].to_numpy()\n",
    "if ta ==2:\n",
    "    testass = size10.iloc[:,10:20].to_numpy()\n",
    "if ta ==3:\n",
    "    testass = industry10.iloc[:,1:11].to_numpy()\n",
    "if ta ==4:\n",
    "    testass = FFFactors[['SMB','HML']].to_numpy()\n",
    "\n",
    "# deal with missing values\n",
    "testass[testass == -99.99] = 0\n",
    "# check size of test assets: 25 portfolios / 10 size deciles/ 10 industry\n",
    "n = testass.shape[1]\n",
    "\n",
    "if ta == 0:\n",
    "    rmx = FF3['MKT-RF'].to_numpy().reshape(-1,1) # market excess return \n",
    "    rf = FF3['RF'].to_numpy().reshape(-1,1) # risk free rate\n",
    "    smb = FF3['SMB'].to_numpy().reshape(-1,1)\n",
    "    hml = FF3['HML'].to_numpy().reshape(-1,1)\n",
    "    ff3 = FF3[['MKT-RF', 'SMB', 'HML']].to_numpy()#Fama French 3 factor\n",
    "    tax = np.subtract(testass, rf)\n",
    "elif 0<ta<4:\n",
    "    tax = np.subtract(testass, rf)\n",
    "else:\n",
    "    tax = testass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e02c8a",
   "metadata": {},
   "source": [
    "# Part 1.\n",
    "## a). Regress each return on the market return and generate a set of alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9fa84959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********************OLS TIME SERIES******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q1 (a)\n",
    "#******************************************************************************\n",
    "print('\\n\\n\\n\\n\\n')\n",
    "print('********************OLS TIME SERIES******************************')\n",
    "#******TIME SERIES REGRESSION*****************\n",
    "model = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "X = ff3\n",
    "Y = tax\n",
    "regressor = model.fit(X, Y)\n",
    "\n",
    "# retrieving the coefficient and intercept\n",
    "b = regressor.coef_ \n",
    "a = regressor.intercept_\n",
    "\n",
    "#******CALCULATE MOMENTS***************** ######%%%%%%%%%%%%%%%\n",
    "mnxret = np.mean(tax, axis = 0) # mean (excess) test assets returns (dimension: num test assets*1)\n",
    "mnff3 = np.mean(np.mean(ff3, axis = 0)) # mean return for the factors\n",
    "capt = len(rf) # length of data\n",
    "varf = (1/(capt-1))* np.sum(np.square(ff3 - mnff3)) # sample variance of market excess return\n",
    "sigf = np.sqrt(varf) # sample volatility of market excess return\n",
    "fsharpe = mnff3/sigf\n",
    "\n",
    "#*********PLOTS RETURNS AND THE MARKET SHARPE RATIO LINE***************\n",
    "#plt.plot(b, mnxret, 'o', 1, mnrmx,'kx', [0, 1.5],[0, 1.5*mnrmx],'k-') #return as dot, [1, mnrmx] as the E[rm], line as the SR line\n",
    "#minr = min(np.append([0], mnxret))\n",
    "#plt.axis([0, 1.5, minr, 1.2])\n",
    "#plt.title(\"OLS Time Series\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "699450c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covf = np.dot(ff3.transpose(), ff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3776e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33635.5430, 6343.3179, 5376.5409],\n",
       "       [6343.3179, 11653.3176, 1566.3764],\n",
       "       [5376.5409, 1566.3764, 14813.2701]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(ff3.transpose(), ff3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb3d00",
   "metadata": {},
   "source": [
    "## b). Calculate the covariance of the alphas assuming\n",
    "i). No correlation among the alphas.\n",
    "\n",
    "ii). No temporal correlation among the alphas.\n",
    "\n",
    "iii). Temporal correlation at one lag.\n",
    "\n",
    "iv). Using the Newey-West kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2c87db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q1 (b)\n",
    "#******************************************************************************\n",
    "\n",
    "#*********GET RESIDUALS AND COVARIANCE MATRICES*****************\n",
    "\n",
    "# residuals (Dimension: capt*1) ##u = Y-Xb'-a, dim: capt*25 for ff25\n",
    "u = Y - np.dot(X, b.transpose()) - np.multiply(np.asarray(np.ones(capt)).reshape(capt,1), a.transpose())#####%%%%%%%%%%\n",
    "\n",
    "# Q1 (b) ii: iid through time but may be cross-sectionally correlated\n",
    "covmat = (1/(capt-1)) * np.dot(u.transpose(), u)  \n",
    "\n",
    "# Q1 (b) i: assuming residuals are uncorrelated (not a good assumption, just for comparison)\n",
    "covnoc = np.diag(np.diag(covmat)) #make the diagnoal element a matrix  \n",
    "\n",
    "# Q1 (b) iii: one lag of autocorrelations;\n",
    "#This is using the NW(1987) Bartlett weight 2*(1-i/(m+1));                           \n",
    "cov1l = covmat + (1/(capt-2)) * np.dot(u[:-1,:].transpose(), u[1:,:])\n",
    "#Alternative is Hansen-Hodrick (see Cochrane p. 210);                     \n",
    "cov1l = covmat + (2/(capt-2)) * np.dot(u[:-1,:].transpose(), u[1:,:])  \n",
    "\n",
    "# Q1 (b) iv: Four lags, Newey-West (Bartlett) weights;\n",
    "cov4l = covmat \n",
    "# For how to choose mm, see NW(1994) \"Automatic lag selection...\" \n",
    "mm = 4                      \n",
    "for i in range(1, mm+1):\n",
    "    w = 1 - i/(mm+1)\n",
    "    cov4l = cov4l + 2*w*(1/(capt-1-i))*np.dot(u[:-i,:].transpose(), u[i:,:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "abb1fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.dot(u.transpose(), u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bb8795f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.dot(ff3.transpose(), ff3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bc3dd",
   "metadata": {},
   "source": [
    "## c). The code calculates the following test statistics for each of the assumed covariance matrices of alpha above\n",
    "i). The OLS asymptotic chi-squared statistics and p-values\n",
    "\n",
    "ii). The GRS finite-sample F statistics and p-values\n",
    "\n",
    "iii). GMM time series asymptotic (chi-squared) and finite sample (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8fdfae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\n",
      "\n",
      "[509.8947 120.2343 121.1118 117.6167]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n",
      "GRS finite-sample test-statistic\n",
      "\n",
      "[19.9355 4.7008 4.7351 4.5985]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************\n",
    "# Q1 (c)\n",
    "#******************************************************************************\n",
    "\n",
    "#**********CALCULATE TEST STATISTICS ASSUMING FACTOR RETURNS AND TESTMAT RESIDUALS INDEPENDENT*********; \n",
    "#See Cochrane p. 230;\n",
    "# Q1 (c) i: With errors that are i.i.d over time, homoskedastic and independent of the factors, \n",
    "# the asymptotic joint distribution of the intercepts gives the model test statistic Chi-Square\n",
    "\n",
    "prechi = capt * (1/(1+np.square(fsharpe)))#######%%%%%%\n",
    "alphvec = a.reshape(-1,1)\n",
    "\n",
    "chi_noc = (prechi*alphvec.transpose()@inv(covnoc)@alphvec).item()\n",
    "chi_reg = (prechi*alphvec.transpose()@inv(covmat)@alphvec).item()\n",
    "chi_1l = (prechi*alphvec.transpose()@inv(cov1l)@alphvec).item()\n",
    "chi_4l = (prechi*alphvec.transpose()@inv(cov4l)@alphvec).item()\n",
    "\n",
    "\n",
    "chis = np.array([chi_noc, chi_reg, chi_1l, chi_4l])\n",
    "pchi = np.ones(4)-chi2.cdf(chis,n)\n",
    "\n",
    "# print the result\n",
    "print('OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\\n')  \n",
    "print(chis)\n",
    "print(pchi)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# See Cochrane p. 230\n",
    "# Q1 (c) ii: With errors are normally distributed, GRS test gives a multivariate, finite-sample test statistic\n",
    "pref = ((capt-n-1)/n) * (1/(1+np.square(fsharpe)))\n",
    "fs = np.multiply(chis, np.divide(pref, prechi))\n",
    "pf = np.ones(4) - list(f.cdf(fs,n,capt-n-1))\n",
    "\n",
    "# print the result\n",
    "print('GRS finite-sample test-statistic\\n')\n",
    "print(fs)\n",
    "print(pf)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "443edbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM Results Time-Series asymptotic \n",
      "\n",
      "[389.0632 135.9143 143.3972 141.0208]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n",
      "GMM Results Time-Series finite sample \n",
      "\n",
      "[15.2113 5.3139 5.6064 5.5135]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Q1 (c) iii:\n",
    "#******************************************************;\n",
    "#  GMM Time-Series (Allows More General Errors)        ;\n",
    "#               See p. 234 Cochrane                    ;\n",
    "#******************************************************;\n",
    "mnff32 = np.mean(np.square(ff3))\n",
    "\n",
    "#first displayed formula, top of 234;\n",
    "d = - np.kron([[1, mnff3.item((0,))], [mnff3.item((0,)), mnff32]],np.eye(n))\n",
    "u_x = np.multiply(u, np.dot(ff3, np.ones((3,n))))#########%%%%%%%\n",
    "uu = np.concatenate((u, u_x), axis=1)\n",
    "\n",
    "cmuu = (1/(capt-1)) * np.dot(uu.transpose(), uu)#No temporal correlation\n",
    "cmuu_noc = np.diag(np.diag(cmuu))#nocorrelation\n",
    "\n",
    "# %NW version 1 lag;\n",
    "c1luu = cmuu + (1/(capt-2)) * np.dot(uu[:-1,:].transpose(), uu[1:,:]) \n",
    "# %Hansen-Hodrick version 1 lag;\n",
    "c1luu = cmuu + (2/(capt-2)) * np.dot(uu[:-1,:].transpose(), uu[1:,:])   \n",
    "\n",
    "# %NW general\n",
    "c4luu = cmuu;   \n",
    "mm = 4;\n",
    "for i in range(1, mm+1):\n",
    "    w = 1 - i/(mm+1);\n",
    "    c4luu = c4luu + 2*w*(1/(capt-1-i))*np.dot(uu[:-i,:].transpose(), uu[i:,:])  \n",
    "\n",
    "dinv = inv(d);\n",
    "vp1 = (1/capt) * dinv@cmuu_noc@dinv.transpose()\n",
    "vp2 = (1/capt) * dinv@cmuu@dinv.transpose()\n",
    "vp3 = (1/capt) * dinv@c1luu@dinv.transpose()\n",
    "vp4 = (1/capt) * dinv@c4luu@dinv.transpose()\n",
    "\n",
    "sdb1 = np.sqrt(np.diag(vp1)).transpose()\n",
    "sdb2 = np.sqrt(np.diag(vp2)).transpose()\n",
    "sdb3 = np.sqrt(np.diag(vp3)).transpose()\n",
    "sdb4 = np.sqrt(np.diag(vp4)).transpose()\n",
    "\n",
    "wt1 = inv(vp1[0:n, 0:n])\n",
    "wt2 = inv(vp2[0:n, 0:n])\n",
    "wt3 = inv(vp3[0:n, 0:n])\n",
    "wt4 = inv(vp4[0:n, 0:n])\n",
    "\n",
    "chi2a = (alphvec.transpose()@wt1@alphvec).item()\n",
    "chi2b = (alphvec.transpose()@wt2@alphvec).item()\n",
    "chi2c = (alphvec.transpose()@wt3@alphvec).item()\n",
    "chi2d = (alphvec.transpose()@wt4@alphvec).item()\n",
    "\n",
    "chis2 = np.array([chi2a,chi2b,chi2c,chi2d])\n",
    "\n",
    "pchi2 = np.ones(4) - chi2.cdf(chis2,n)\n",
    "\n",
    "print('GMM Results Time-Series asymptotic \\n')\n",
    "print(chis2)\n",
    "print(pchi2)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "fs2 = np.multiply(chis2, np.divide(pref, prechi))\n",
    "pf2 = np.ones(4) - list(f.cdf(fs2,n,capt-n-1))\n",
    "\n",
    "print('GMM Results Time-Series finite sample \\n');\n",
    "print(fs2)\n",
    "print(pf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2b0bbfb",
   "metadata": {},
   "source": [
    "## Part 2.a The cross-sectional approach\n",
    "Using the betas previously estimated, run cross-sectional regression to estimate\n",
    "the market price of risk. Enforce the assumption that the zero beta portfolio has\n",
    "zero excess return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1948f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********************OLS CROSS SECTIONAL******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q2 (a)\n",
    "#******************************************************************************\n",
    "\n",
    "#*********CROSS-SECTIONAL REGRESSIONS;**********************************\n",
    "\n",
    "print('\\n\\n\\n\\n\\n')\n",
    "print('********************OLS CROSS SECTIONAL******************************')\n",
    "\n",
    "#  %See p. 237 of Cochrane;\n",
    "#%Putting a constant here would allow the zero beta portfolio to be unrestricted;\n",
    "X = b # beta estimate from time-series regression     \n",
    "Y = mnxret\n",
    "\n",
    "model = LinearRegression(fit_intercept=False, normalize=False, copy_X=True, n_jobs=None) #notice no intercept here\n",
    "regressor = model.fit(X, Y)\n",
    "\n",
    "# retrieving the coefficient\n",
    "lam = regressor.coef_ # lambda: risk premia\n",
    "\n",
    "alphcs = Y.reshape(-1,1) - np.dot(X, lam).reshape(-1, 1) #####Y.reshape(-1,1) - np.multiply(X, lam) # alpha estimation\n",
    "\n",
    "xxinv = inv(np.dot(X.transpose(), X))\n",
    "cap = np.eye(n) - multi_dot([X, xxinv, X.transpose()]) # I - X(X'X)^(-1)X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b29f8959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y.reshape(-1,1) - np.dot(X, lam).reshape(-1, 1))#- np.multiply(X, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f62282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f8087",
   "metadata": {},
   "source": [
    "## Part 2.b \n",
    "The code calculates the following test statistics assuming each of the error\n",
    "structures in 1b\n",
    "\n",
    "### i) OLS asymptotic chi-squared statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fa9d3816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(covalph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b69035b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(alphcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5680b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1074 0.0831 0.0808 0.0936 0.0939 0.0972 0.0656 0.0603 0.0637 0.0698\n",
      " 0.1058 0.0633 0.0547 0.0539 0.0674 0.1130 0.0697 0.0553 0.0548 0.0698\n",
      " 0.1115 0.0717 0.0523 0.0505 0.0679]\n",
      "[0.0903 0.0643 0.0700 0.0846 0.0777 0.0821 0.0497 0.0584 0.0585 0.0485\n",
      " 0.0798 0.0451 0.0495 0.0520 0.0443 0.0809 0.0467 0.0476 0.0535 0.0424\n",
      " 0.0879 0.0514 0.0497 0.0595 0.0584]\n",
      "[0.0859 0.0649 0.0684 0.0927 0.0716 0.0887 0.0458 0.0524 0.0608 0.0485\n",
      " 0.0857 0.0413 0.0482 0.0527 0.0458 0.0792 0.0449 0.0491 0.0564 0.0422\n",
      " 0.0817 0.0469 0.0494 0.0604 0.0624]\n",
      "[0.0926 0.0668 0.0694 0.0967 0.0788 0.0885 0.0471 0.0518 0.0605 0.0485\n",
      " 0.0853 0.0408 0.0478 0.0548 0.0466 0.0834 0.0458 0.0486 0.0579 0.0451\n",
      " 0.0865 0.0507 0.0497 0.0585 0.0632]\n",
      "[0.2170 0.2260 0.2269 0.2277]\n",
      "OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\n",
      "\n",
      "[235.4260 111.2438 107.3279 104.5899]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Q2 (b) i\n",
    "#####################################################################################\n",
    "# variance of lambda estimation and variance of lambda estimation\n",
    "# assume that residuals are not correlated --> the covariance variance matrix \\Lamba in (12.12) and (12.13)\n",
    "#####################################################################################\n",
    "# here it seems that the variance covariance matrix of factors is missing from  \n",
    "# the matlab formula when error and factors are iid\n",
    "#####################################################################################\n",
    "\n",
    "# factors and errors are iid through time\n",
    "varlam1 = (1/capt) * (xxinv * multi_dot([X.transpose(), covnoc, X]) * xxinv + varf)\n",
    "covalph1 = (1/capt) * multi_dot([cap, covnoc, cap]) \n",
    "\n",
    "# iid through time but may be cross-sectionally correlated\n",
    "varlam2 = (1/capt) * (xxinv * multi_dot([X.transpose(), covmat, X]) * xxinv + varf)\n",
    "covalph2 = (1/capt) * multi_dot([cap, covmat, cap])\n",
    "\n",
    "# 1 lag of autocorrelations\n",
    "varlam3 = (1/capt) * (xxinv * multi_dot([X.transpose(), cov1l, X]) * xxinv + varf)\n",
    "covalph3 = (1/capt) * multi_dot([cap, cov1l, cap])\n",
    "\n",
    "# 4 lags of autocorrelations\n",
    "varlam4 = (1/capt) * (xxinv * multi_dot([X.transpose(), cov4l, X]) * xxinv + varf)\n",
    "covalph4 = (1/capt) * multi_dot([cap, cov4l, cap])\n",
    "\n",
    "sealph1 = np.sqrt(np.diag(covalph1)).transpose()\n",
    "sealph2 = np.sqrt(np.diag(covalph2)).transpose()\n",
    "sealph3 = np.sqrt(np.diag(covalph3)).transpose()\n",
    "sealph4 = np.sqrt(np.diag(covalph4)).transpose()\n",
    "\n",
    "alphcsp = alphcs.transpose()\n",
    "\n",
    "# standard error of estimated alpha\n",
    "print(sealph1)\n",
    "print(sealph2)\n",
    "print(sealph3)\n",
    "print(sealph4)\n",
    "\n",
    "# standard error of estimated lambda\n",
    "siglam = np.sqrt([varlam1.item(0, 0), varlam2.item(0, 0), varlam3.item(0, 0), varlam4.item(0, 0)])\n",
    "print(siglam)\n",
    "\n",
    "# the Moore-Penrose pseudo inverse of matrix\n",
    "chi2_1 = (alphcs.transpose()@pinv(covalph1)@alphcs).item()\n",
    "chi2_2 = (alphcs.transpose()@pinv(covalph2)@alphcs).item()\n",
    "chi2_3 = (alphcs.transpose()@pinv(covalph3)@alphcs).item()\n",
    "chi2_4 = (alphcs.transpose()@pinv(covalph4)@alphcs).item()\n",
    "\n",
    "chivec = np.array([chi2_1, chi2_2, chi2_3, chi2_4])\n",
    "pchi = 1 - chi2.cdf(chivec, n-1)\n",
    "\n",
    "print('OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\\n')  \n",
    "print(chivec)\n",
    "print(pchi)\n",
    "\n",
    "\n",
    "#plt.plot(b, mnxret, 'o', 1,mnrmx,'kx', [0, 1.5],[0, 1.5*lam],'k--')\n",
    "#plt.plot([0, 1.5],[0, 1.5*lam],'k--')\n",
    "#minr = min(np.append([0], mnxret))\n",
    "#plt.axis([0, 1.5, minr, 1.2])\n",
    "\n",
    "#plt.title(\"OLS Cross Sectional\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d5b8d",
   "metadata": {},
   "source": [
    "### ii) OLS with the Shanken correction for estimation error in the first-stage estimated betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e56ebdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inv(np.asarray(varf).reshape(1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "30c79139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0193, 0.0193, 0.0193]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(np.asarray(varf).reshape(1, 1))*np.ones(3)#.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4ae77de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0077])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam.transpose()@(inv(np.asarray(varf).reshape(1, 1))*np.ones(3)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "df629f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7151, 0.7112, -1.0302])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f949c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014610988141678283"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam.transpose()@inv(covf)@lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "03de0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "************************** Shanken Correction OLS *************************** \n",
      "[[[5.4037 2.3466 2.1607]\n",
      "  [2.3466 3.1816 1.1679]\n",
      "  [2.1607 1.1679 3.5906]]\n",
      "\n",
      " [[5.4040 2.3467 2.1618]\n",
      "  [2.3467 3.1831 1.1721]\n",
      "  [2.1618 1.1721 3.6076]]\n",
      "\n",
      " [[5.4041 2.3467 2.1618]\n",
      "  [2.3467 3.1830 1.1716]\n",
      "  [2.1618 1.1721 3.6073]]\n",
      "\n",
      " [[5.4041 2.3467 2.1620]\n",
      "  [2.3467 3.1834 1.1724]\n",
      "  [2.1619 1.1728 3.6090]]]\n",
      "[0.1074 0.0831 0.0809 0.0936 0.0939 0.0972 0.0656 0.0603 0.0637 0.0698\n",
      " 0.1058 0.0633 0.0547 0.0539 0.0674 0.1130 0.0697 0.0553 0.0548 0.0698\n",
      " 0.1115 0.0717 0.0523 0.0505 0.0679]\n",
      "[0.0904 0.0643 0.0700 0.0846 0.0777 0.0821 0.0497 0.0584 0.0585 0.0485\n",
      " 0.0798 0.0451 0.0495 0.0520 0.0443 0.0809 0.0467 0.0476 0.0535 0.0424\n",
      " 0.0879 0.0514 0.0497 0.0595 0.0584]\n",
      "[0.0859 0.0649 0.0684 0.0927 0.0716 0.0887 0.0458 0.0524 0.0608 0.0485\n",
      " 0.0858 0.0413 0.0482 0.0527 0.0458 0.0792 0.0449 0.0491 0.0564 0.0422\n",
      " 0.0817 0.0469 0.0494 0.0604 0.0624]\n",
      "[0.0926 0.0668 0.0694 0.0967 0.0788 0.0885 0.0471 0.0518 0.0605 0.0485\n",
      " 0.0853 0.0408 0.0478 0.0548 0.0466 0.0834 0.0458 0.0486 0.0579 0.0451\n",
      " 0.0865 0.0507 0.0497 0.0585 0.0632]\n",
      "\n",
      "\n",
      "OLS with Shanken correction for estimatin error in the first-stage estimated betas\n",
      "\n",
      "[235.3916 111.2276 107.3122 104.5746]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Q2 (b) ii\n",
    "#*************************************************************************************;\n",
    "# Shanken Correction, addressing the fact that our beta is estimated using time-series regression \n",
    "# See p. 239 of Cochrane, equation (12.19)\n",
    "print('\\n\\n\\n');\n",
    "print('************************** Shanken Correction OLS *************************** ')\n",
    "\n",
    "mc = 1 + lam.transpose()@inv(covf)@lam\n",
    "ac = covf#varrmx\n",
    "\n",
    "varlam1s = (1/capt) * xxinv * multi_dot([X.transpose(), covnoc, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam2s = (1/capt) * xxinv * multi_dot([X.transpose(), covmat, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam3s = (1/capt) * xxinv * multi_dot([X.transpose(), cov1l, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam4s = (1/capt) * xxinv * multi_dot([X.transpose(), cov4l, X]) * xxinv * mc + (1/capt)*ac\n",
    "\n",
    "siglams = np.sqrt([varlam1s, varlam2s, varlam3s, varlam4s])\n",
    "print(siglams)\n",
    "\n",
    "covalph1s = covalph1*mc\n",
    "covalph2s = covalph2*mc\n",
    "covalph3s = covalph3*mc\n",
    "covalph4s = covalph4*mc\n",
    "\n",
    "sealph1s = np.sqrt(np.diag(covalph1s)).transpose()\n",
    "sealph2s = np.sqrt(np.diag(covalph2s)).transpose()\n",
    "sealph3s = np.sqrt(np.diag(covalph3s)).transpose()\n",
    "sealph4s = np.sqrt(np.diag(covalph4s)).transpose()\n",
    "\n",
    "print(sealph1s)\n",
    "print(sealph2s)\n",
    "print(sealph3s)\n",
    "print(sealph4s)\n",
    "\n",
    "chi1s = (alphcs.transpose()@pinv(covalph1s)@alphcs).item() #(1,1) array\n",
    "chi2s = (alphcs.transpose()@pinv(covalph2s)@alphcs).item()\n",
    "chi3s = (alphcs.transpose()@pinv(covalph3s)@alphcs).item()\n",
    "chi4s = (alphcs.transpose()@pinv(covalph4s)@alphcs).item()\n",
    "\n",
    "print('\\n');\n",
    "print('OLS with Shanken correction for estimatin error in the first-stage estimated betas\\n')  \n",
    "chivecs = np.array([chi1s, chi2s, chi3s, chi4s])\n",
    "pchis = 1 - chi2.cdf(chivecs, n-1)\n",
    "\n",
    "print(chivecs)\n",
    "print(pchis)\n",
    "\n",
    "\n",
    "print('\\n\\n\\n\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d948694",
   "metadata": {},
   "source": [
    "### iii) GLS with and without the Shanken correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f9ff7937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********GLS Cross-Section (Assume iid)********* \n",
      "[0.7089 0.2846 0.1231]\n",
      "[5.4035 3.1809 3.5883]\n",
      "[0.1103 0.0635 0.0624 0.0894 0.0993 0.0945 0.0502 0.0493 0.0579 0.0610\n",
      " 0.1039 0.0510 0.0447 0.0503 0.0559 0.1160 0.0612 0.0480 0.0513 0.0634\n",
      " 0.1200 0.0640 0.0389 0.0419 0.0638]\n",
      "\n",
      "\n",
      "GLS without Shanken correction\n",
      "\n",
      "[[111.2438]]\n",
      "[[0.0000]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#**************************\n",
    "#    GLS Cross-Section    ;\n",
    "#**************************\n",
    "#See Cochrane p.238, \n",
    "#Betas estimated more efficiently; \n",
    "\n",
    "###############################################################################\n",
    "#matlab code also misses the covariance variance matrix of factors\n",
    "###############################################################################\n",
    "print('***********GLS Cross-Section (Assume iid)********* ')\n",
    "\n",
    "lamg = inv(X.transpose()@inv(covmat)@X)@X.transpose()@inv(covmat)@Y # (12.15)\n",
    "print(lamg)\n",
    "\n",
    "agls = Y.reshape(-1,1) - np.dot(X, lamg).reshape(-1,1)########%%%%%changed multiply to dot\n",
    "#%%\n",
    "#plt.plot(b, mnxret, 'o', 1,mnrmx,'kx',[0, 1.5],[0, 1.5*lamg.item()],'k:')\n",
    "#plt.title(\"GLS Cross Sectional\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "#plt.show()\n",
    "#%%\n",
    "\n",
    "varlamg = (1/capt) * inv(X.transpose()@inv(covmat)@X) + (1/capt) * covf # (12.16)\n",
    "#varlamg = (1/capt) * inv(X.transpose()@inv(covmat)@X)\n",
    "cova = (1/capt) * (covmat - X@inv(X.transpose()@inv(covmat)@X)@X.transpose()) #(12.17)\n",
    "\n",
    "selamg = np.sqrt(np.diag(varlamg)).transpose()\n",
    "sea = np.sqrt(np.diag(cova)).transpose()\n",
    "\n",
    "print(selamg)\n",
    "print(sea)\n",
    "#%%\n",
    "aglsp = agls.transpose()\n",
    "\n",
    "chigls = capt * agls.transpose()@inv(covmat)@agls # (12.18)\n",
    "pchigls = 1 - chi2.cdf(chigls,n-1);\n",
    "\n",
    "print('\\n');\n",
    "print('GLS without Shanken correction\\n')  \n",
    "print(chigls)\n",
    "print(pchigls)\n",
    "\n",
    "print('\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "63e51008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********GLS Cross-Section Shanken Correction (Assume iid)********* \n",
      "[5.4035 3.1809 3.5883]\n",
      "[0.1103 0.0635 0.0624 0.0894 0.0993 0.0945 0.0502 0.0493 0.0579 0.0610\n",
      " 0.1039 0.0510 0.0447 0.0503 0.0559 0.1160 0.0612 0.0480 0.0513 0.0634\n",
      " 0.1200 0.0640 0.0389 0.0419 0.0638]\n",
      "\n",
      "\n",
      "GLS with Shanken correction\n",
      "\n",
      "[[111.2601]]\n",
      "[[0.0000]]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#****************************************************\n",
    "#GLS Cross-Section Shanken Correction;  \n",
    "#****************************************************\n",
    "#See Cochrane p. 239\n",
    "print('***********GLS Cross-Section Shanken Correction (Assume iid)********* ')\n",
    "\n",
    "# varlamgs is also wrong in matlab code\n",
    "varlamgs = (1/capt) * inv(X.transpose()@inv(covmat)@X)*mc + (1/capt)*ac #(12.19)\n",
    "covas = cova*mc\n",
    "\n",
    "selamgs = np.sqrt(np.diag(varlamgs)).transpose()\n",
    "seas = np.sqrt(np.diag(covas)).transpose()\n",
    "\n",
    "print(selamgs)\n",
    "print(seas)\n",
    "#%%\n",
    "chiglss = capt * agls.transpose()@inv(covmat)@agls * mc #(12.21)\n",
    "pchiglss = 1 - chi2.cdf(chiglss,n-1)\n",
    "\n",
    "print('\\n');\n",
    "print('GLS with Shanken correction\\n')  \n",
    "print(chiglss)\n",
    "print(pchiglss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6339f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "OLS Cross-Section by GMM (general errors)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [221]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m     11\u001b[0m a_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn), np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn,n))), axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m---> 12\u001b[0m a_2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((a_1, a_2), axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m     15\u001b[0m d_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39meye(n), np\u001b[38;5;241m.\u001b[39meye(n)\u001b[38;5;241m*\u001b[39mmnrmx, np\u001b[38;5;241m.\u001b[39mzeros((n,\u001b[38;5;241m1\u001b[39m))), axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3"
     ]
    }
   ],
   "source": [
    "#*****************************************************;\n",
    "#OLS Cross-Section by GMM;\n",
    "#See Cochrane p. 241 - 243;\n",
    "#******************************************************;\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print('OLS Cross-Section by GMM (general errors)')\n",
    "\n",
    "X = b\n",
    "\n",
    "a_1 = np.concatenate((np.eye(2*n), np.zeros((2*n,n))), axis =1) \n",
    "a_2 = np.concatenate((np.zeros((1,2*n)), X.transpose()), axis = 1)\n",
    "a = np.concatenate((a_1, a_2), axis =0) \n",
    "\n",
    "d_1 = np.concatenate((np.eye(n), np.eye(n)*mnrmx, np.zeros((n,1))), axis =1) \n",
    "d_2 = np.concatenate((np.eye(n)*mnrmx, np.eye(n)*mnrmx2, np.zeros((n,1))), axis =1) \n",
    "d_3 = np.concatenate((np.zeros((n,n)), lam*np.eye(n), X), axis =1) \n",
    "d = -np.concatenate((d_1, d_2, d_3), axis =0)\n",
    "  \n",
    "uu = np.concatenate((u, np.multiply(u, rmx*np.ones((1,n))), tax-np.dot(np.ones((capt,1)), X.transpose())*lam), axis = 1)\n",
    "cmuu = (1/(capt-1)) * np.dot(uu.transpose(), uu)\n",
    "cmuu_noc = np.diag(np.diag(cmuu))\n",
    "\n",
    "c1luu = cmuu + (1/(capt-2)) * np.dot(uu[:-1,:].transpose(), uu[1:,:])\n",
    "c4luu = cmuu\n",
    "for i in range(2, 5):\n",
    "  w = 1 - i/5\n",
    "  c4luu = c4luu + 2*w*(1/(capt-1-i))*np.dot(uu[0:-i,:].transpose(), uu[i:,:])\n",
    "\n",
    "invad = inv(np.dot(a,d))\n",
    "varb2 = (1/capt)* multi_dot([invad, a, cmuu, a.transpose(), invad])\n",
    "\n",
    "premom = np.subtract(np.eye(3*n), multi_dot([d, invad, a]))\n",
    "varmom1 = (1/capt)*multi_dot([premom, cmuu_noc, premom.transpose()])\n",
    "varmom2 = (1/capt)*multi_dot([premom, cmuu, premom.transpose()])\n",
    "varmom3 = (1/capt)*multi_dot([premom, c1luu, premom.transpose()])\n",
    "varmom4 = (1/capt)*multi_dot([premom, c4luu, premom.transpose()])\n",
    "\n",
    "alph = np.mean(uu[:,2*n:], axis = 0)\n",
    "chi21 = multi_dot([alph, pinv(varmom1[2*n:,2*n:]), alph.transpose()])\n",
    "chi22 = multi_dot([alph, pinv(varmom2[2*n:,2*n:]), alph.transpose()])\n",
    "chi23 = multi_dot([alph, pinv(varmom3[2*n:,2*n:]), alph.transpose()])\n",
    "chi24 = multi_dot([alph, pinv(varmom4[2*n:,2*n:]), alph.transpose()])\n",
    "chi2og = np.array([chi21, chi22, chi23, chi24])\n",
    "\n",
    "pchi2og = 1 - chi2.cdf(chi2og,n-1);\n",
    "\n",
    "print('\\n');\n",
    "print(chi2og)\n",
    "print(pchi2og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1ed04664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "GLS Cross-Section by GMM (general errors)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [222]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLS Cross-Section by GMM (general errors)\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[1;32m      7\u001b[0m a_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn), np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn,n))), axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m----> 8\u001b[0m a_2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     10\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((a_1, a_2), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m invadg \u001b[38;5;241m=\u001b[39m inv(np\u001b[38;5;241m.\u001b[39mdot(a, d))\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#*************************************;\n",
    "#GLS Cross-Section by GMM;\n",
    "print('\\n\\n\\n');\n",
    "print('GLS Cross-Section by GMM (general errors)');\n",
    "\n",
    "a_1 = np.concatenate((np.eye(2*n), np.zeros((2*n,n))), axis =1) \n",
    "a_2 = np.concatenate((np.zeros((1, 2*n)), np.dot(X.transpose(), inv(covmat))), axis =1) \n",
    "\n",
    "a = np.concatenate((a_1, a_2), axis=0)\n",
    "\n",
    "invadg = inv(np.dot(a, d))\n",
    "varb2g = (1/capt)*multi_dot([invadg, a, cmuu, a.transpose(), invadg])\n",
    "\n",
    "premomg = np.eye(3*n)-multi_dot([d, invadg, a])\n",
    "varmom1g = (1/capt)*multi_dot([premomg, cmuu_noc, premomg.transpose()])\n",
    "varmom2g = (1/capt)*multi_dot([premomg, cmuu, premomg.transpose()])\n",
    "varmom3g = (1/capt)*multi_dot([premomg, c1luu, premomg.transpose()])\n",
    "varmom4g = (1/capt)*multi_dot([premomg, c4luu, premomg.transpose()])\n",
    "\n",
    "alph = np.mean(uu[:,2*n:], axis = 0)\n",
    "chi21g = multi_dot([alph, pinv(varmom1g[2*n:,2*n:]), alph.transpose()])\n",
    "chi22g = multi_dot([alph, pinv(varmom2g[2*n:,2*n:]), alph.transpose()])\n",
    "chi23g = multi_dot([alph, pinv(varmom3g[2*n:,2*n:]), alph.transpose()])\n",
    "chi24g = multi_dot([alph, pinv(varmom4g[2*n:,2*n:]), alph.transpose()])\n",
    "chi2g = np.array([chi21g, chi22g, chi23g, chi24g])\n",
    "\n",
    "pchi2g = 1 - chi2.cdf(chi2g,n-1)\n",
    "\n",
    "print('\\n');\n",
    "print(chi2g)\n",
    "print(pchi2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b259d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc9cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dd0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8424c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb0449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8ac2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226076a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81ac1a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 25)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a737250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3],[3, 4, 5]])\n",
    "b = np.array([[4], [5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81eb0d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b276848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccf1cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False, normalize=False, copy_X=True, n_jobs=None) #notice no intercept here\n",
    "regressor = model.fit(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8acf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = regressor.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "052ff6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3333, 3.6667, -1.0000],\n",
       "       [9.0000, 4.3333, -3.3333]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(-1,1) - np.multiply(a, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e80b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxinv = inv(np.dot(a.transpose(), a))\n",
    "cap = np.eye(2) - multi_dot([a, xxinv, a.transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc8285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
