{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae270dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import f\n",
    "from numpy.linalg import multi_dot\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import pinv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e2116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set format of the output\n",
    "float_formatter = \"{:.4f}\".format # keep 4 digits\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "#******************************************************************************\n",
    "# Define Paths + Read in Data + Clean Data\n",
    "#******************************************************************************\n",
    "# define paths of files \n",
    "path = os.getcwd() + \"/Data\"\n",
    "\n",
    "# path = '/Users/keling/Dropbox/Courses/Keling/aptest_keling/Data'\n",
    "FFFactors_path = '/factors/FFFactors.txt'\n",
    "FF25_path = '/FF25/ff25vm.txt'\n",
    "size10_path = '/size10/sizevm.txt'\n",
    "industry10_path = '/industry10/ind10vm.txt'\n",
    "sm25_path = '/SM/25sm.txt'\n",
    "FF3New_path = '/FF3/ff3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "FFFactors = pd.read_csv(path + FFFactors_path, header = None, delim_whitespace=True)\n",
    "FFFactors.columns = ['time', 'MKT-RF', 'SMB','HML', 'RF']\n",
    "\n",
    "# transform into matrix form\n",
    "rmx = FFFactors['MKT-RF'].to_numpy().reshape(-1,1) # market excess return \n",
    "rf = FFFactors['RF'].to_numpy().reshape(-1,1) # risk free rate\n",
    "\n",
    "FF25 = pd.read_csv(path + FF25_path, header = None, delim_whitespace=True)\n",
    "size10 = pd.read_csv(path + size10_path, header = None, delim_whitespace=True)\n",
    "industry10 = pd.read_csv(path + industry10_path, header = None, delim_whitespace=True)\n",
    "sm25 = pd.read_csv(path + sm25_path, header = None, delim_whitespace=True)\n",
    "FF3 = pd.read_csv(path + FF3New_path, header = None, delim_whitespace=True)\n",
    "FF3.columns = ['time', 'MKT-RF', 'SMB','HML', 'RF']\n",
    "# select test assets\n",
    "# ta = 1: Fama-French 25 portfolios\n",
    "# ta = 2: 10 size deciles\n",
    "# ta = 3: 10 industry portfolios\n",
    "# ta = 4: size and value factors - SMB and HML\n",
    "\n",
    "ta = 0\n",
    "if ta ==0:\n",
    "    testass = sm25.iloc[:,1:26].to_numpy()\n",
    "if ta ==1:\n",
    "    testass = FF25.iloc[:,1:26].to_numpy()\n",
    "if ta ==2:\n",
    "    testass = size10.iloc[:,10:20].to_numpy()\n",
    "if ta ==3:\n",
    "    testass = industry10.iloc[:,1:11].to_numpy()\n",
    "if ta ==4:\n",
    "    testass = FFFactors[['SMB','HML']].to_numpy()\n",
    "\n",
    "# deal with missing values\n",
    "testass[testass == -99.99] = 0\n",
    "# check size of test assets: 25 portfolios / 10 size deciles/ 10 industry\n",
    "n = testass.shape[1]\n",
    "\n",
    "if ta == 0:\n",
    "    rmx = FF3['MKT-RF'].to_numpy().reshape(-1,1) # market excess return \n",
    "    rf = FF3['RF'].to_numpy().reshape(-1,1) # risk free rate\n",
    "    smb = FF3['SMB'].to_numpy().reshape(-1,1)\n",
    "    hml = FF3['HML'].to_numpy().reshape(-1,1)\n",
    "    ff3 = FF3[['MKT-RF', 'SMB', 'HML']].to_numpy()#Fama French 3 factor\n",
    "    tax = np.subtract(testass, rf)\n",
    "elif 0<ta<4:\n",
    "    tax = np.subtract(testass, rf)\n",
    "else:\n",
    "    tax = testass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f173f",
   "metadata": {},
   "source": [
    "# Part 1.\n",
    "## a). Regress each return on the market return and generate a set of alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "467ce005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********************OLS TIME SERIES******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q1 (a)\n",
    "#******************************************************************************\n",
    "print('\\n\\n\\n\\n\\n')\n",
    "print('********************OLS TIME SERIES******************************')\n",
    "#******TIME SERIES REGRESSION*****************\n",
    "model = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "X = ff3\n",
    "Y = tax\n",
    "regressor = model.fit(X, Y)\n",
    "\n",
    "# retrieving the coefficient and intercept\n",
    "b = regressor.coef_ \n",
    "a = regressor.intercept_\n",
    "\n",
    "#******CALCULATE MOMENTS***************** ######%%%%%%%%%%%%%%%\n",
    "mnxret = np.mean(tax, axis = 0) # mean (excess) test assets returns (dimension: num test assets*1)\n",
    "mnff3 = np.mean(ff3, axis = 0) # mean return for the factors\n",
    "capt = len(rf) # length of data\n",
    "covf = (1/(capt-1))* np.dot((ff3-mnff3).transpose(), (ff3-mnff3)) # sample variance of market excess return\n",
    "#sigf = np.sqrt(varf) # sample volatility of market excess return\n",
    "#fsharpe = mnff3/sigf\n",
    "\n",
    "#*********PLOTS RETURNS AND THE MARKET SHARPE RATIO LINE***************\n",
    "#plt.plot(b, mnxret, 'o', 1, mnrmx,'kx', [0, 1.5],[0, 1.5*mnrmx],'k-') #return as dot, [1, mnrmx] as the E[rm], line as the SR line\n",
    "#minr = min(np.append([0], mnxret))\n",
    "#plt.axis([0, 1.5, minr, 1.2])\n",
    "#plt.title(\"OLS Time Series\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2926ab7",
   "metadata": {},
   "source": [
    "## b). Calculate the covariance of the alphas assuming\n",
    "i). No correlation among the alphas.\n",
    "\n",
    "ii). No temporal correlation among the alphas.\n",
    "\n",
    "iii). Temporal correlation at one lag.\n",
    "\n",
    "iv). Using the Newey-West kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7514a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q1 (b)\n",
    "#******************************************************************************\n",
    "\n",
    "#*********GET RESIDUALS AND COVARIANCE MATRICES*****************\n",
    "\n",
    "# residuals (Dimension: capt*1) ##u = Y-Xb'-a, dim: capt*25 for ff25\n",
    "u = Y - np.dot(X, b.transpose()) - np.multiply(np.asarray(np.ones(capt)).reshape(capt,1), a.transpose())#####%%%%%%%%%%\n",
    "\n",
    "# Q1 (b) ii: iid through time but may be cross-sectionally correlated\n",
    "covmat = (1/(capt-1)) * np.dot(u.transpose(), u)  \n",
    "\n",
    "# Q1 (b) i: assuming residuals are uncorrelated (not a good assumption, just for comparison)\n",
    "covnoc = np.diag(np.diag(covmat)) #make the diagnoal element a matrix  \n",
    "\n",
    "# Q1 (b) iii: one lag of autocorrelations;\n",
    "#This is using the NW(1987) Bartlett weight 2*(1-i/(m+1));                           \n",
    "cov1l = covmat + (1/(capt-2)) * np.dot(u[:-1,:].transpose(), u[1:,:])\n",
    "#Alternative is Hansen-Hodrick (see Cochrane p. 210);                     \n",
    "cov1l = covmat + (2/(capt-2)) * np.dot(u[:-1,:].transpose(), u[1:,:])  \n",
    "\n",
    "# Q1 (b) iv: Four lags, Newey-West (Bartlett) weights;\n",
    "cov4l = covmat \n",
    "# For how to choose mm, see NW(1994) \"Automatic lag selection...\" \n",
    "mm = 4                      \n",
    "for i in range(1, mm+1):\n",
    "    w = 1 - i/(mm+1)\n",
    "    cov4l = cov4l + 2*w*(1/(capt-1-i))*np.dot(u[:-i,:].transpose(), u[i:,:])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ecdf9",
   "metadata": {},
   "source": [
    "## c). The code calculates the following test statistics for each of the assumed covariance matrices of alpha above\n",
    "i). The OLS asymptotic chi-squared statistics and p-values\n",
    "\n",
    "ii). The GRS finite-sample F statistics and p-values\n",
    "\n",
    "iii). GMM time series asymptotic (chi-squared) and finite sample (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b9afec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\n",
      "\n",
      "[500.8556 118.1028 118.9648 115.5317]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n",
      "GRS finite-sample test-statistic\n",
      "\n",
      "[[19.5473 4.6093 4.6429 4.5089]]\n",
      "[[0.0000 0.0000 0.0000 0.0000]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************\n",
    "# Q1 (c)\n",
    "#******************************************************************************\n",
    "\n",
    "#**********CALCULATE TEST STATISTICS ASSUMING FACTOR RETURNS AND TESTMAT RESIDUALS INDEPENDENT*********; \n",
    "#See Cochrane p. 230;\n",
    "# Q1 (c) i: With errors that are i.i.d over time, homoskedastic and independent of the factors, \n",
    "# the asymptotic joint distribution of the intercepts gives the model test statistic Chi-Square\n",
    "\n",
    "prechi = capt * inv(1 + mnff3.reshape(-1,1).transpose()@inv(covf)@mnff3.reshape(-1,1))\n",
    "#######%%%%%% E_T(f)'\\Omega^{-1}E_T(f) p.231 (12.3)\n",
    "alphvec = a.reshape(-1,1)\n",
    "\n",
    "chi_noc = (prechi*alphvec.transpose()@inv(covnoc)@alphvec).item()\n",
    "chi_reg = (prechi*alphvec.transpose()@inv(covmat)@alphvec).item()\n",
    "chi_1l = (prechi*alphvec.transpose()@inv(cov1l)@alphvec).item()\n",
    "chi_4l = (prechi*alphvec.transpose()@inv(cov4l)@alphvec).item()\n",
    "\n",
    "\n",
    "chis = np.array([chi_noc, chi_reg, chi_1l, chi_4l])\n",
    "pchi = np.ones(4)-chi2.cdf(chis,n)\n",
    "\n",
    "# print the result\n",
    "print('OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\\n')  \n",
    "print(chis)\n",
    "print(pchi)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# See Cochrane p. 230\n",
    "# Q1 (c) ii: With errors are normally distributed, GRS test gives a multivariate, finite-sample test statistic\n",
    "pref = ((capt-n-3)/n) * (1/(1+mnff3.reshape(-1,1).transpose()@inv(covf)@mnff3.reshape(-1,1))) \n",
    "#######%%%%%%k = 3 for three factor p.231 (12.4)\n",
    "fs = np.multiply(chis, np.divide(pref, prechi))\n",
    "pf = np.ones(4) - list(f.cdf(fs,n,capt-n-3))#####%%%% k = 3\n",
    "\n",
    "# print the result\n",
    "print('GRS finite-sample test-statistic\\n')\n",
    "print(fs)\n",
    "print(pf)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847d740",
   "metadata": {},
   "source": [
    "#### For the GMM Time series:\n",
    "We find it difficult to code everything out, so we provide suedo code and intuition here.\n",
    "\n",
    "- Step1: Calculate the $d$ matrix, which is 4*4 in this case. Let $X = [1 \\; f_{mkt} \\; f_{sml} \\; f_{hml}]$, $d = -dotproduct(E(X'X), I_N)$\n",
    "- Step2: Calculate the $S$ matrix, which is also 4*4 and it will be different for each type of covariance matrices of the error. The basic idea is let $W = [\\epsilon \\; f_{mkt}\\epsilon \\; f_{sml}\\epsilon \\; f_{hml}\\epsilon]$ (where $\\epsilon$ here is just a general form it will depend on which of the four types of error matrices we use.) Then $S = E(W'W)$\n",
    "- Step3: Obtain $var(\\hat{\\alpha})$ from $var([\\hat{\\alpha} \\; \\hat{\\beta}]') = \\frac{1}{T}d^{-1}Sd^{-1}$\n",
    "- Step4: Calculate the test statistic by $\\hat{\\alpha}'var{\\hat{\\alpha}}\\hat{\\alpha}$ ~ $\\chi_N^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af126d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec06f43",
   "metadata": {},
   "source": [
    "## Part 2.a The cross-sectional approach\n",
    "Using the betas previously estimated, run cross-sectional regression to estimate\n",
    "the market price of risk. Enforce the assumption that the zero beta portfolio has\n",
    "zero excess return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66b6011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********************OLS CROSS SECTIONAL******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "# Q2 (a)\n",
    "#******************************************************************************\n",
    "\n",
    "#*********CROSS-SECTIONAL REGRESSIONS;**********************************\n",
    "\n",
    "print('\\n\\n\\n\\n\\n')\n",
    "print('********************OLS CROSS SECTIONAL******************************')\n",
    "\n",
    "#  %See p. 237 of Cochrane;\n",
    "#%Putting a constant here would allow the zero beta portfolio to be unrestricted;\n",
    "X = b # beta estimate from time-series regression     \n",
    "Y = mnxret\n",
    "\n",
    "model = LinearRegression(fit_intercept=False, normalize=False, copy_X=True, n_jobs=None) #notice no intercept here\n",
    "regressor = model.fit(X, Y)\n",
    "\n",
    "# retrieving the coefficient\n",
    "lam = regressor.coef_ # lambda: risk premia\n",
    "\n",
    "alphcs = Y.reshape(-1,1) - np.dot(X, lam).reshape(-1, 1) #####Y.reshape(-1,1) - np.multiply(X, lam) # alpha estimation\n",
    "\n",
    "xxinv = inv(np.dot(X.transpose(), X))\n",
    "cap = np.eye(n) - multi_dot([X, xxinv, X.transpose()]) # I - X(X'X)^(-1)X'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089bba18",
   "metadata": {},
   "source": [
    "## Part 2.b \n",
    "The code calculates the following test statistics assuming each of the error\n",
    "structures in 1b\n",
    "\n",
    "### i) OLS asymptotic chi-squared statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "19be0efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1074 0.0831 0.0808 0.0936 0.0939 0.0972 0.0656 0.0603 0.0637 0.0698\n",
      " 0.1058 0.0633 0.0547 0.0539 0.0674 0.1130 0.0697 0.0553 0.0548 0.0698\n",
      " 0.1115 0.0717 0.0523 0.0505 0.0679]\n",
      "[0.0903 0.0643 0.0700 0.0846 0.0777 0.0821 0.0497 0.0584 0.0585 0.0485\n",
      " 0.0798 0.0451 0.0495 0.0520 0.0443 0.0809 0.0467 0.0476 0.0535 0.0424\n",
      " 0.0879 0.0514 0.0497 0.0595 0.0584]\n",
      "[0.0859 0.0649 0.0684 0.0927 0.0716 0.0887 0.0458 0.0524 0.0608 0.0485\n",
      " 0.0857 0.0413 0.0482 0.0527 0.0458 0.0792 0.0449 0.0491 0.0564 0.0422\n",
      " 0.0817 0.0469 0.0494 0.0604 0.0624]\n",
      "[0.0926 0.0668 0.0694 0.0967 0.0788 0.0885 0.0471 0.0518 0.0605 0.0485\n",
      " 0.0853 0.0408 0.0478 0.0548 0.0466 0.0834 0.0458 0.0486 0.0579 0.0451\n",
      " 0.0865 0.0507 0.0497 0.0585 0.0632]\n",
      "[0.0249 0.0279 0.0281 0.0266]\n",
      "OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\n",
      "\n",
      "[235.4260 111.2438 107.3279 104.5899]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Q2 (b) i\n",
    "#####################################################################################\n",
    "# variance of lambda estimation and variance of lambda estimation\n",
    "# assume that residuals are not correlated --> the covariance variance matrix \\Lamba in (12.12) and (12.13)\n",
    "#####################################################################################\n",
    "# here it seems that the variance covariance matrix of factors is missing from  \n",
    "# the matlab formula when error and factors are iid\n",
    "#####################################################################################\n",
    "\n",
    "# factors and errors are iid through time\n",
    "#varlam1 = (1/capt) * (xxinv * multi_dot([X.transpose(), covnoc, X]) * xxinv + varf)\n",
    "varlam1 = (1/capt) * (xxinv @ multi_dot([X.transpose(), covnoc, X]) @ xxinv)\n",
    "covalph1 = (1/capt) * multi_dot([cap, covnoc, cap]) \n",
    "\n",
    "# iid through time but may be cross-sectionally correlated\n",
    "#varlam2 = (1/capt) * (xxinv * multi_dot([X.transpose(), covmat, X]) * xxinv + varf)\n",
    "varlam2 = (1/capt) * (xxinv @ multi_dot([X.transpose(), covmat, X]) @ xxinv)\n",
    "covalph2 = (1/capt) * multi_dot([cap, covmat, cap])\n",
    "\n",
    "# 1 lag of autocorrelations\n",
    "#varlam3 = (1/capt) * (xxinv * multi_dot([X.transpose(), cov1l, X]) * xxinv + varf)\n",
    "varlam3 = (1/capt) * (xxinv @ multi_dot([X.transpose(), cov1l, X]) @ xxinv)\n",
    "covalph3 = (1/capt) * multi_dot([cap, cov1l, cap])\n",
    "\n",
    "# 4 lags of autocorrelations\n",
    "#varlam4 = (1/capt) * (xxinv * multi_dot([X.transpose(), cov4l, X]) * xxinv + varf)\n",
    "varlam4 = (1/capt) * (xxinv @ multi_dot([X.transpose(), cov4l, X]) @ xxinv)\n",
    "covalph4 = (1/capt) * multi_dot([cap, cov4l, cap])\n",
    "\n",
    "sealph1 = np.sqrt(np.diag(covalph1)).transpose()\n",
    "sealph2 = np.sqrt(np.diag(covalph2)).transpose()\n",
    "sealph3 = np.sqrt(np.diag(covalph3)).transpose()\n",
    "sealph4 = np.sqrt(np.diag(covalph4)).transpose()\n",
    "\n",
    "alphcsp = alphcs.transpose()\n",
    "\n",
    "# standard error of estimated alpha\n",
    "print(sealph1)\n",
    "print(sealph2)\n",
    "print(sealph3)\n",
    "print(sealph4)\n",
    "\n",
    "# standard error of estimated lambda\n",
    "siglam = np.sqrt([varlam1.item(0, 0), varlam2.item(0, 0), varlam3.item(0, 0), varlam4.item(0, 0)])\n",
    "print(siglam)\n",
    "\n",
    "# the Moore-Penrose pseudo inverse of matrix\n",
    "chi2_1 = (alphcs.transpose()@pinv(covalph1)@alphcs).item()\n",
    "chi2_2 = (alphcs.transpose()@pinv(covalph2)@alphcs).item()\n",
    "chi2_3 = (alphcs.transpose()@pinv(covalph3)@alphcs).item()\n",
    "chi2_4 = (alphcs.transpose()@pinv(covalph4)@alphcs).item()\n",
    "\n",
    "chivec = np.array([chi2_1, chi2_2, chi2_3, chi2_4])\n",
    "pchi = 1 - chi2.cdf(chivec, n-3)####k = 3\n",
    "\n",
    "print('OLS asymptotic test statistics (Chi-Square), assuming factor returns and testmat residuals are independent\\n')  \n",
    "print(chivec)\n",
    "print(pchi)\n",
    "\n",
    "\n",
    "#plt.plot(b, mnxret, 'o', 1,mnrmx,'kx', [0, 1.5],[0, 1.5*lam],'k--')\n",
    "#plt.plot([0, 1.5],[0, 1.5*lam],'k--')\n",
    "#minr = min(np.append([0], mnxret))\n",
    "#plt.axis([0, 1.5, minr, 1.2])\n",
    "\n",
    "#plt.title(\"OLS Cross Sectional\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62a3a3",
   "metadata": {},
   "source": [
    "### ii) OLS with the Shanken correction for estimation error in the first-stage estimated betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e47ae217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "************************** Shanken Correction OLS *************************** \n",
      "[[[0.1660 0.0702 0.0753]\n",
      "  [0.0702 0.1292 0.0779]\n",
      "  [0.0753 0.0779 0.2245]]\n",
      "\n",
      " [[0.1795 0.0735 0.1056]\n",
      "  [0.0735 0.1665 0.1328]\n",
      "  [0.1056 0.1328 0.4392]]\n",
      "\n",
      " [[0.1807 0.0736 0.1063]\n",
      "  [0.0734 0.1652 0.1279]\n",
      "  [0.1067 0.1330 0.4367]]\n",
      "\n",
      " [[0.1820 0.0745 0.1098]\n",
      "  [0.0738 0.1732 0.1354]\n",
      "  [0.1088 0.1401 0.4525]]]\n",
      "[0.1161 0.0898 0.0874 0.1012 0.1015 0.1051 0.0709 0.0652 0.0689 0.0755\n",
      " 0.1144 0.0684 0.0591 0.0582 0.0729 0.1221 0.0753 0.0598 0.0592 0.0755\n",
      " 0.1205 0.0775 0.0565 0.0546 0.0734]\n",
      "[0.0977 0.0695 0.0757 0.0914 0.0839 0.0887 0.0537 0.0632 0.0633 0.0524\n",
      " 0.0863 0.0488 0.0535 0.0562 0.0479 0.0874 0.0505 0.0515 0.0578 0.0458\n",
      " 0.0950 0.0556 0.0537 0.0643 0.0631]\n",
      "[0.0928 0.0701 0.0740 0.1002 0.0773 0.0958 0.0495 0.0567 0.0657 0.0525\n",
      " 0.0927 0.0447 0.0521 0.0570 0.0495 0.0856 0.0486 0.0531 0.0609 0.0457\n",
      " 0.0883 0.0507 0.0534 0.0653 0.0674]\n",
      "[0.1001 0.0722 0.0750 0.1045 0.0851 0.0957 0.0510 0.0560 0.0653 0.0524\n",
      " 0.0922 0.0441 0.0517 0.0592 0.0503 0.0902 0.0495 0.0525 0.0626 0.0488\n",
      " 0.0935 0.0548 0.0538 0.0632 0.0683]\n",
      "\n",
      "\n",
      "OLS with Shanken correction for estimatin error in the first-stage estimated betas\n",
      "\n",
      "[201.5311 95.2278 91.8756 89.5318]\n",
      "[0.0000 0.0000 0.0000 0.0000]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Q2 (b) ii\n",
    "#*************************************************************************************;\n",
    "# Shanken Correction, addressing the fact that our beta is estimated using time-series regression \n",
    "# See p. 239 of Cochrane, equation (12.19)\n",
    "print('\\n\\n\\n');\n",
    "print('************************** Shanken Correction OLS *************************** ')\n",
    "\n",
    "mc = 1 + lam.transpose()@inv(covf)@lam #######%%%%%%%change inv(np.asarray(varrmx).reshape(1,1)) to inv(covf)\n",
    "ac = covf#######%%%%%%%change varrmx to covf\n",
    "\n",
    "varlam1s = (1/capt) * xxinv * multi_dot([X.transpose(), covnoc, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam2s = (1/capt) * xxinv * multi_dot([X.transpose(), covmat, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam3s = (1/capt) * xxinv * multi_dot([X.transpose(), cov1l, X]) * xxinv * mc + (1/capt)*ac\n",
    "varlam4s = (1/capt) * xxinv * multi_dot([X.transpose(), cov4l, X]) * xxinv * mc + (1/capt)*ac\n",
    "\n",
    "siglams = np.sqrt([varlam1s, varlam2s, varlam3s, varlam4s])\n",
    "print(siglams)\n",
    "\n",
    "covalph1s = covalph1*mc\n",
    "covalph2s = covalph2*mc\n",
    "covalph3s = covalph3*mc\n",
    "covalph4s = covalph4*mc\n",
    "\n",
    "sealph1s = np.sqrt(np.diag(covalph1s)).transpose()\n",
    "sealph2s = np.sqrt(np.diag(covalph2s)).transpose()\n",
    "sealph3s = np.sqrt(np.diag(covalph3s)).transpose()\n",
    "sealph4s = np.sqrt(np.diag(covalph4s)).transpose()\n",
    "\n",
    "print(sealph1s)\n",
    "print(sealph2s)\n",
    "print(sealph3s)\n",
    "print(sealph4s)\n",
    "\n",
    "chi1s = (alphcs.transpose()@pinv(covalph1s)@alphcs).item() #(1,1) array\n",
    "chi2s = (alphcs.transpose()@pinv(covalph2s)@alphcs).item()\n",
    "chi3s = (alphcs.transpose()@pinv(covalph3s)@alphcs).item()\n",
    "chi4s = (alphcs.transpose()@pinv(covalph4s)@alphcs).item()\n",
    "\n",
    "print('\\n');\n",
    "print('OLS with Shanken correction for estimatin error in the first-stage estimated betas\\n')  \n",
    "chivecs = np.array([chi1s, chi2s, chi3s, chi4s])\n",
    "pchis = 1 - chi2.cdf(chivecs, n-3)####%%%% k = 3\n",
    "\n",
    "print(chivecs)\n",
    "print(pchis)\n",
    "\n",
    "\n",
    "print('\\n\\n\\n\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c158c4",
   "metadata": {},
   "source": [
    "### iii) GLS with and without the Shanken correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47a3c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********GLS Cross-Section (Assume iid)********* \n",
      "[0.7089 0.2846 0.1231]\n",
      "[0.1595 0.1043 0.1687]\n",
      "[0.1103 0.0635 0.0624 0.0894 0.0993 0.0945 0.0502 0.0493 0.0579 0.0610\n",
      " 0.1039 0.0510 0.0447 0.0503 0.0559 0.1160 0.0612 0.0480 0.0513 0.0634\n",
      " 0.1200 0.0640 0.0389 0.0419 0.0638]\n",
      "\n",
      "\n",
      "GLS without Shanken correction\n",
      "\n",
      "[[111.2438]]\n",
      "[[0.0000]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#**************************\n",
    "#    GLS Cross-Section    ;\n",
    "#**************************\n",
    "#See Cochrane p.238, \n",
    "#Betas estimated more efficiently; \n",
    "\n",
    "###############################################################################\n",
    "#matlab code also misses the covariance variance matrix of factors\n",
    "###############################################################################\n",
    "print('***********GLS Cross-Section (Assume iid)********* ')\n",
    "\n",
    "lamg = inv(X.transpose()@inv(covmat)@X)@X.transpose()@inv(covmat)@Y # (12.15)\n",
    "print(lamg)\n",
    "\n",
    "agls = Y.reshape(-1,1) - np.dot(X, lamg).reshape(-1,1)########%%%%%changed multiply to dot\n",
    "#%%\n",
    "#plt.plot(b, mnxret, 'o', 1,mnrmx,'kx',[0, 1.5],[0, 1.5*lamg.item()],'k:')\n",
    "#plt.title(\"GLS Cross Sectional\")\n",
    "#plt.xlabel(r\"$\\beta$\")\n",
    "#plt.ylabel(r\"$E[R^{e}]$\")\n",
    "#plt.show()\n",
    "#%%\n",
    "\n",
    "varlamg = (1/capt) * inv(X.transpose()@inv(covmat)@X) + (1/capt) * covf # (12.16) ######%%%%%covf\n",
    "#varlamg = (1/capt) * inv(X.transpose()@inv(covmat)@X)\n",
    "cova = (1/capt) * (covmat - X@inv(X.transpose()@inv(covmat)@X)@X.transpose()) #(12.17)\n",
    "\n",
    "selamg = np.sqrt(np.diag(varlamg)).transpose()\n",
    "sea = np.sqrt(np.diag(cova)).transpose()\n",
    "\n",
    "print(selamg)\n",
    "print(sea)\n",
    "#%%\n",
    "aglsp = agls.transpose()\n",
    "\n",
    "chigls = capt * agls.transpose()@inv(covmat)@agls # (12.18)\n",
    "pchigls = 1 - chi2.cdf(chigls,n-1);\n",
    "\n",
    "print('\\n');\n",
    "print('GLS without Shanken correction\\n')  \n",
    "print(chigls)\n",
    "print(pchigls)\n",
    "\n",
    "print('\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "901a0498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********GLS Cross-Section Shanken Correction (Assume iid)********* \n",
      "[0.1597 0.1060 0.1772]\n",
      "[0.1192 0.0686 0.0674 0.0966 0.1073 0.1021 0.0543 0.0533 0.0626 0.0659\n",
      " 0.1123 0.0551 0.0483 0.0544 0.0605 0.1254 0.0662 0.0519 0.0554 0.0686\n",
      " 0.1297 0.0692 0.0420 0.0453 0.0689]\n",
      "\n",
      "\n",
      "GLS with Shanken correction\n",
      "\n",
      "[[129.9536]]\n",
      "[[0.0000]]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#****************************************************\n",
    "#GLS Cross-Section Shanken Correction;  \n",
    "#****************************************************\n",
    "#See Cochrane p. 239\n",
    "print('***********GLS Cross-Section Shanken Correction (Assume iid)********* ')\n",
    "\n",
    "# varlamgs is also wrong in matlab code\n",
    "varlamgs = (1/capt) * inv(X.transpose()@inv(covmat)@X)*mc + (1/capt)*ac #(12.19)\n",
    "covas = cova*mc\n",
    "\n",
    "selamgs = np.sqrt(np.diag(varlamgs)).transpose()\n",
    "seas = np.sqrt(np.diag(covas)).transpose()\n",
    "\n",
    "print(selamgs)\n",
    "print(seas)\n",
    "#%%\n",
    "chiglss = capt * agls.transpose()@inv(covmat)@agls * mc #(12.21)\n",
    "pchiglss = 1 - chi2.cdf(chiglss,n-1)\n",
    "\n",
    "print('\\n');\n",
    "print('GLS with Shanken correction\\n')  \n",
    "print(chiglss)\n",
    "print(pchiglss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe001bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e162c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d080cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dedecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a92fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d725d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e998d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574eede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
